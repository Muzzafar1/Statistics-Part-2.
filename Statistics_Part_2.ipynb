{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q 1: What is hypothesis testing in statistics ?\n",
        "\n",
        "- Hypothesis testing is a statistical method used to make decisions or inferences about population parameters based on sample data. It involves formulating two competing hypotheses and determining which one is better supported by the data.\n",
        "\n",
        "Q 2: What is the null hypothesis, and how does it differ from the alternative hypothesis?\n",
        "\n",
        "- The null hypothesis is a statement of \"no effect\" or \"no difference,\" while the alternative hypothesis is a statement that contradicts the null hypothesis, suggesting there is a real effect or difference. Essentially, the null hypothesis is what researchers try to disprove, while the alternative is what they aim to prove.\n",
        "\n",
        "Q 3: What is the significance level in hypothesis testing, and why is it important ?\n",
        "\n",
        "- In hypothesis testing, the significance level (denoted by α, alpha) is the probability of rejecting the null hypothesis when it is actually true. It represents the researcher's willingness to accept a Type I error, which is falsely rejecting a true null hypothesis. It's a crucial threshold for determining statistical significance, helping researchers decide whether observed results are likely due to chance or a real effect.\n",
        "\n",
        "Q 4: What does a P-value represent in hypothesis testing ?\n",
        "\n",
        "- In hypothesis testing, a P-value represents the probability of obtaining results as extreme as, or more extreme than, the observed results, assuming the null hypothesis is true. Essentially, it quantifies the evidence against the null hypothesis. A smaller P-value indicates stronger evidence against the null hypothesis, suggesting that the observed results are unlikely to have occurred by random chance alone.\n",
        "\n",
        "Q 5:How do you interpret the P-value in hypothesis testing ?\n",
        "- In hypothesis testing, the p-value represents the probability of obtaining results as extreme as, or more extreme than, the observed results, assuming the null hypothesis is true. A smaller p-value indicates stronger evidence against the null hypothesis. Conventionally, if the p-value is less than or equal to a predetermined significance level (often 0.05), the null hypothesis is rejected.\n",
        "\n",
        "Q 6: What are Type 1 and Type 2 errors in hypothesis testing ?\n",
        "\n",
        "- In hypothesis testing, a Type I error (false positive) occurs when the null hypothesis is rejected, even though it's actually true. A Type II error (false negative) occurs when the null hypothesis is not rejected, even though it's actually false.\n",
        "\n",
        "Q 7:What is the difference between a one-tailed and a two-tailed test in hypothesis testing ?\n",
        "\n",
        "- In hypothesis testing, a one-tailed test examines if a parameter is significantly greater or less than a specific value, while a two-tailed test examines if a parameter is significantly different from a specific value, without specifying the direction of the difference. .\n",
        "\n",
        "Q 8: What is the Z-test, and when is it used in hypothesis testing ?\n",
        "\n",
        "- A z-test is a statistical hypothesis test used to determine if there's a significant difference between a sample mean and a population mean, or between the means of two independent samples, when the population variance is known or the sample size is large. It's typically used when dealing with data that follows a normal distribution.\n",
        "\n",
        "Q 9:  How do you calculate the Z-score, and what does it represent in hypothesis testing ?\n",
        "\n",
        "- The Z-score is calculated using the following formula:\n",
        "Z = (x - μ) / σ\n",
        "Where:\n",
        "- x: is the data point (or sample mean)\n",
        "- μ: is the population mean\n",
        "- σ: is the population standard deviation\n",
        "\n",
        " A Z-score measures how many standard deviations a data point is from the mean of a dataset. In hypothesis testing, it's used to determine the probability of obtaining a result as extreme as, or more extreme than, the one observed, assuming the null hypothesis is true. It helps determine if a sample mean is significantly different from a population mean.\n",
        "\n",
        "\n",
        " Q 10: What is the T-distribution, and when should it be used instead of the normal distribution ?\n",
        " - The t-distribution, also known as Student's t-distribution, is a probability distribution used in statistics, particularly when dealing with small sample sizes or when the population standard deviation is unknown. It is preferred over the normal distribution in these situations because it accounts for the increased uncertainty associated with estimating population parameters from limited data.\n",
        "\n",
        "\n",
        " Q 11: What is the difference between a Z-test and a T-test ?\n",
        " - The main difference between a Z-test and a T-test lies in the knowledge of the population standard deviation and the sample size. Z-tests are used when the population standard deviation is known or when the sample size is large (typically greater than 30), while T-tests are used when the population standard deviation is unknown and the sample size is small (typically less than 30)\n",
        "\n",
        "\n",
        " Q 12: What is the T-test, and how is it used in hypothesis testing ?\n",
        " - A t-test is a statistical hypothesis test used to determine if there's a significant difference between the means of two groups. It's a common tool in hypothesis testing, particularly when dealing with smaller sample sizes or when the population standard deviation is unknown. The t-test helps assess whether observed differences between groups are likely due to a real effect or simply random chance.\n",
        "\n",
        "\n",
        " Q 13: What is the relationship between Z-test and T-test in hypothesis testing ?\n",
        " - Both Z-tests and T-tests are used in hypothesis testing to compare means, but they differ in their assumptions and when they are most appropriate. Z-tests are used when the population standard deviation is known and the sample size is large (typically 30 or more). T-tests are used when the population standard deviation is unknown and/or the sample size is small (typically less than 30).\n",
        "\n",
        "\n",
        " Q 14: What is a confidence interval, and how is it used to interpret statistical results ?\n",
        " - A confidence interval (CI) is a range of values that is likely to contain the true value of a population parameter, such as the mean or proportion. It provides a measure of uncertainty around a sample statistic and is used to interpret statistical results by indicating the precision of an estimate and the potential range of the true population value.\n",
        "\n",
        "\n",
        " Q 15: What is the margin of error, and how does it affect the confidence interval ?\n",
        " - The margin of error is a statistical measure of how much the results of a survey or study might differ from the true population value. It's a range of values, typically expressed as a plus or minus percentage, that indicates the potential variability in your results. A smaller margin of error means your results are more precise and likely closer to the true population value.\n",
        "\n",
        "\n",
        " Q 16: How is Bayes' Theorem used in statistics, and what is its significance ?\n",
        "\n",
        " - Bayes' theorem is a fundamental concept in probability and statistics that provides a way to update the probability of an event based on new evidence. It allows statisticians to combine prior knowledge with observed data to refine their understanding of probabilities, making it a crucial tool for inference and decision-making.\n",
        "\n",
        "\n",
        " Q 17: What is the Chi-square distribution, and when is it used ?\n",
        " - The chi-square distribution is a family of continuous probability distributions, used primarily in hypothesis testing, particularly for categorical data. It's used to determine if there's a significant difference between observed and expected frequencies, or to assess the independence of categorical variables.\n",
        "\n",
        "\n",
        " Q 18: What is the Chi-square goodness of fit test, and how is it applied ?\n",
        " - The chi-square goodness-of-fit test is a statistical test used to determine if a sample distribution matches a known or expected distribution. It assesses how well observed frequencies of a categorical variable align with expected frequencies based on a theoretical distribution. Essentially, it checks if the differences between what's observed and what's expected are due to chance or if there's a significant discrepency.\n",
        "\n",
        "\n",
        " Q 19: What is the F-distribution, and when is it used in hypothesis testing ?/\n",
        " - The F-distribution is a probability distribution that arises frequently in hypothesis testing, particularly when comparing variances or means of multiple groups. It is used to determine if there is a statistically significant difference between the variances of two or more populations or to test the overall significance of a regression model.\n",
        "\n",
        "\n",
        " Q 20: What is an ANOVA test, and what are its assumptions ?\n",
        " - ANOVA (Analysis of Variance) is a statistical test used to compare the means of three or more groups. It determines if there are any statistically significant differences between the group means, indicating that the observed differences are likely not due to random chance.\n",
        " - Assumptions of ANOVA:\n",
        "- 1. Normality:\n",
        "The data within each group being compared should be approximately normally distributed. This means the data should follow a bell-shaped curve with most values clustered around the mean.\n",
        "- 2. Homogeneity of Variance (Homoscedasticity):\n",
        "The variance (spread or dispersion) of the data should be roughly equal across all the groups being compared.\n",
        "- 3. Independence of Observations:\n",
        "The observations within each group and between different groups should be independent of each other. This means that the value of one data point should not influence the value of another.\n",
        "\n",
        "Q 21: What are the different types of ANOVA tests ?\n",
        "- The primary types of ANOVA tests are one-way ANOVA and two-way ANOVA. One-way ANOVA is used to compare means of three or more groups based on a single independent variable. Two-way ANOVA, on the other hand, examines the effects of two or more independent variables on a dependent variable, and can also assess interactions between those independent variables.\n",
        "\n",
        "Q 22: What is the F-test, and how does it relate to hypothesis testing ?\n",
        "- The F-test is a statistical test used in hypothesis testing to compare the variances of two or more populations or samples. It is particularly useful for determining if there is a significant difference between the variances of these groups, often as a preliminary step before further analysis. The F-test relies on the F-distribution and the F-statistic, which is a ratio of two variances.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PuR6QUtCPBMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "                      # Practical Part - 1"
      ],
      "metadata": {
        "id": "R7a2puTZ0Zri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Write a Python program to generate a random variable and display its value.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Generate a single random variable from a normal distribution\n",
        "random_value = np.random.normal(loc=0, scale=1)\n",
        "print(\"Random variable from normal distribution:\", random_value)"
      ],
      "metadata": {
        "id": "ez2oEWWXiU3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Generate a discrete uniform distribution using Python and plot the probability mass function (PMF).\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "# Generate discrete uniform data\n",
        "data = np.random.randint(1, 7, size=1000)  # dice roll (1-6)\n",
        "\n",
        "# PMF using counts\n",
        "counter = Counter(data)\n",
        "x = sorted(counter.keys())\n",
        "pmf = [counter[val] / len(data) for val in x]\n",
        "\n",
        "# Plotting PMF\n",
        "plt.stem(x, pmf, use_line_collection=True)\n",
        "plt.title('PMF of Discrete Uniform Distribution (Dice Roll)')\n",
        "plt.xlabel('Outcome')\n",
        "plt.ylabel('Probability')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "epZsoowsiyeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Write a Python function to calculate the probability distribution function (PDF) of a Bernoulli distribution.\n",
        "\n",
        "from scipy.stats import bernoulli\n",
        "\n",
        "# Bernoulli distribution (p=0.6)\n",
        "p = 0.6\n",
        "x = [0, 1]\n",
        "pdf = bernoulli.pmf(x, p)\n",
        "\n",
        "# Display result\n",
        "for val, prob in zip(x, pdf):\n",
        "    print(f\"P(X={val}) = {prob}\")"
      ],
      "metadata": {
        "id": "Wh2NVgXDiyl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Write a Python script to simulate a binomial distribution with n=10 and p=0.5, then plot its histogram.\n",
        "\n",
        "from scipy.stats import binom\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Parameters\n",
        "n, p = 10, 0.5\n",
        "x = np.arange(0, n+1)\n",
        "pmf = binom.pmf(x, n, p)\n",
        "\n",
        "# Plotting\n",
        "plt.bar(x, pmf)\n",
        "plt.title('Binomial Distribution PMF (n=10, p=0.5)')\n",
        "plt.xlabel('Number of Successes')\n",
        "plt.ylabel('Probability')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OajUhkqqiyr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Create a Poisson distribution and visualize it using Python.\n",
        "\n",
        "from scipy.stats import poisson\n",
        "\n",
        "# Parameters\n",
        "mu = 3\n",
        "x = np.arange(0, 10)\n",
        "pmf = poisson.pmf(x, mu)\n",
        "\n",
        "# Plotting\n",
        "plt.stem(x, pmf, use_line_collection=True)\n",
        "plt.title('Poisson Distribution PMF (λ=3)')\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('P(X=k)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-DUbv7V4jUwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Write a Python program to calculate and plot the cumulative distribution function (CDF) of a discrete uniform distribution.\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Discrete uniform distribution (e.g., dice roll 1–6)\n",
        "low, high = 1, 7  # randint is exclusive on the high end\n",
        "x = np.arange(low, high)\n",
        "cdf = randint.cdf(x, low, high)\n",
        "\n",
        "# Plotting\n",
        "plt.step(x, cdf, where='mid', color='green')\n",
        "plt.title('CDF of Discrete Uniform Distribution (Dice Roll)')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Cumulative Probability')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qcNzdeqeiyvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Generate a continuous uniform distribution using NumPy and visualize it.\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate 1000 samples from a uniform distribution between 0 and 1\n",
        "data = np.random.uniform(0, 1, 1000)\n",
        "\n",
        "# Plot histogram\n",
        "plt.hist(data, bins=20, color='skyblue', edgecolor='black', density=True)\n",
        "plt.title('Histogram of Continuous Uniform Distribution')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Density')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7WIx020Iiyzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Simulate data from a normal distribution and plot its histogram.\n",
        "\n",
        "# Generate normal distribution data\n",
        "data = np.random.normal(loc=0, scale=1, size=1000)\n",
        "\n",
        "# Plot histogram\n",
        "plt.hist(data, bins=30, density=True, color='lightcoral', edgecolor='black')\n",
        "plt.title('Histogram of Normal Distribution')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Density')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F3MUmmoCiy37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Write a Python function to calculate Z-scores from a dataset and plot them.\n",
        "\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Sample dataset\n",
        "data = np.random.normal(50, 10, 100)\n",
        "\n",
        "# Calculate Z-scores\n",
        "z_scores = zscore(data)\n",
        "\n",
        "# Plotting\n",
        "plt.plot(z_scores, marker='o', linestyle='none', color='purple')\n",
        "plt.axhline(0, color='black', linestyle='--')\n",
        "plt.title('Z-Scores of Dataset')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Z-Score')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WDVZBjZXiy8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Implement the Central Limit Theorem (CLT) using Python for a non-normal distribution.\n",
        "\n",
        "# Simulate from a non-normal distribution (Exponential)\n",
        "samples = [np.mean(np.random.exponential(scale=2.0, size=30)) for _ in range(1000)]\n",
        "\n",
        "# Plot histogram of sample means\n",
        "plt.hist(samples, bins=30, density=True, color='orange', edgecolor='black')\n",
        "plt.title('Central Limit Theorem Demonstration')\n",
        "plt.xlabel('Sample Mean')\n",
        "plt.ylabel('Density')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A2NJauUPkQGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Simulate multiple samples from a normal distribution and verify the Central Limit Theorem.\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Simulate 1000 sample means, each from a normal distribution\n",
        "sample_means = [np.mean(np.random.normal(loc=50, scale=10, size=30)) for _ in range(1000)]\n",
        "\n",
        "# Plot the distribution of sample means\n",
        "plt.hist(sample_means, bins=30, density=True, color='skyblue', edgecolor='black')\n",
        "plt.title('Central Limit Theorem: Distribution of Sample Means')\n",
        "plt.xlabel('Sample Mean')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6DJuO6N5kVfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Write a Python function to calculate and plot the standard normal distribution (mean = 0, std = 1).\n",
        "\n",
        "from scipy.stats import norm\n",
        "\n",
        "x = np.linspace(-4, 4, 1000)\n",
        "pdf = norm.pdf(x, loc=0, scale=1)\n",
        "\n",
        "plt.plot(x, pdf, color='blue')\n",
        "plt.title('Standard Normal Distribution')\n",
        "plt.xlabel('Z')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AF7GXo_FoPTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 13. Generate random variables and calculate their corresponding probabilities using the binomial distribution.\n",
        "\n",
        "from scipy.stats import binom\n",
        "\n",
        "n, p = 10, 0.5\n",
        "x = np.arange(0, n+1)\n",
        "pmf = binom.pmf(x, n, p)\n",
        "\n",
        "for k, prob in zip(x, pmf):\n",
        "    print(f\"P(X = {k}) = {prob:.4f}\")"
      ],
      "metadata": {
        "id": "VuqzX5f3oWqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 14. Write a Python program to calculate the Z-score for a given data point and compare it to a standard normal distribution.\n",
        "\n",
        "data_point = 72\n",
        "mean = 70\n",
        "std = 5\n",
        "\n",
        "z = (data_point - mean) / std\n",
        "print(f\"Z-score: {z:.2f}\")"
      ],
      "metadata": {
        "id": "Wz4cgcBCoiB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 15. Implement hypothesis testing using Z-statistics for a sample dataset.\n",
        "\n",
        "sample = np.array([52, 55, 53, 51, 50])\n",
        "population_mean = 50\n",
        "sample_mean = np.mean(sample)\n",
        "sample_std = np.std(sample, ddof=1)\n",
        "n = len(sample)\n",
        "\n",
        "z = (sample_mean - population_mean) / (sample_std / np.sqrt(n))\n",
        "p = 2 * (1 - norm.cdf(abs(z)))\n",
        "\n",
        "print(f\"Z = {z:.4f}, P-value = {p:.4f}\")"
      ],
      "metadata": {
        "id": "lkpzugK-ooDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 16. Create a confidence interval for a dataset using Python and interpret the result.\n",
        "\n",
        "import scipy.stats as stats\n",
        "\n",
        "data = np.random.normal(100, 10, 30)\n",
        "mean = np.mean(data)\n",
        "sem = stats.sem(data)\n",
        "confidence = 0.95\n",
        "\n",
        "interval = stats.t.interval(confidence, df=len(data)-1, loc=mean, scale=sem)\n",
        "print(f\"95% Confidence Interval: {interval}\")"
      ],
      "metadata": {
        "id": "Dckyg9suowOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 17. Generate data from a normal distribution, then calculate and interpret the confidence interval for its mean.\n",
        "\n",
        "data = np.random.normal(200, 15, 40)\n",
        "mean = np.mean(data)\n",
        "sem = stats.sem(data)\n",
        "ci = stats.t.interval(0.95, df=len(data)-1, loc=mean, scale=sem)\n",
        "\n",
        "print(f\"Mean: {mean:.2f}\")\n",
        "print(f\"95% Confidence Interval: {ci}\")"
      ],
      "metadata": {
        "id": "jrG8Uvn3o6Wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 18. Write a Python script to calculate and visualize the probability density function (PDF) of a normal distribution.\n",
        "\n",
        "x = np.linspace(60, 140, 1000)\n",
        "pdf = stats.norm.pdf(x, loc=100, scale=15)\n",
        "\n",
        "plt.plot(x, pdf, color='purple')\n",
        "plt.title('PDF of Normal Distribution (mean=100, std=15)')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7w9b2P4xpAiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 19. Use Python to calculate and interpret the cumulative distribution function (CDF) of a Poisson distribution.\n",
        "\n",
        "from scipy.stats import poisson\n",
        "\n",
        "x = np.arange(0, 15)\n",
        "cdf = poisson.cdf(x, mu=5)\n",
        "\n",
        "plt.step(x, cdf, where='mid')\n",
        "plt.title('CDF of Poisson Distribution (λ=5)')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Cumulative Probability')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7YCaTK9dpP3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 20. Simulate a random variable using a continuous uniform distribution and calculate its expected value.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Continuous uniform distribution between 10 and 20\n",
        "data = np.random.uniform(low=10, high=20, size=1000)\n",
        "\n",
        "# Calculate expected value\n",
        "expected_value = np.mean(data)\n",
        "print(f\"Expected Value: {expected_value:.2f}\")"
      ],
      "metadata": {
        "id": "csMoUrHdpUMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 21. Write a Python program to compare the standard deviations of two datasets and visualize the difference.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate two datasets\n",
        "data1 = np.random.normal(50, 5, 100)\n",
        "data2 = np.random.normal(50, 10, 100)\n",
        "\n",
        "std1 = np.std(data1, ddof=1)\n",
        "std2 = np.std(data2, ddof=1)\n",
        "\n",
        "print(f\"Standard Deviation of Data1: {std1:.2f}\")\n",
        "print(f\"Standard Deviation of Data2: {std2:.2f}\")\n",
        "\n",
        "# Plot\n",
        "plt.hist(data1, bins=20, alpha=0.6, label='Data1 (std=5)')\n",
        "plt.hist(data2, bins=20, alpha=0.6, label='Data2 (std=10)')\n",
        "plt.title('Comparison of Standard Deviations')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ilYzQBIrqAO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 22. Calculate the range and interquartile range (IQR) of a dataset generated from a normal distribution.\n",
        "\n",
        "# Generate data\n",
        "data = np.random.normal(100, 20, 100)\n",
        "\n",
        "# Calculate range\n",
        "data_range = np.max(data) - np.min(data)\n",
        "\n",
        "# Calculate IQR\n",
        "q1 = np.percentile(data, 25)\n",
        "q3 = np.percentile(data, 75)\n",
        "iqr = q3 - q1\n",
        "\n",
        "print(f\"Range: {data_range:.2f}\")\n",
        "print(f\"IQR: {iqr:.2f}\")"
      ],
      "metadata": {
        "id": "Fhk32fwhqGbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 23. Implement Z-score normalization on a dataset and visualize its transformation.\n",
        "\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Original data\n",
        "original_data = np.random.normal(70, 15, 100)\n",
        "\n",
        "# Z-score normalization\n",
        "z_normalized = zscore(original_data)\n",
        "\n",
        "# Plotting\n",
        "plt.hist(original_data, bins=20, alpha=0.6, label='Original')\n",
        "plt.hist(z_normalized, bins=20, alpha=0.6, label='Z-score Normalized')\n",
        "plt.title('Z-score Normalization Comparison')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gsEm7Cq5qMd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 24. Write a Python function to calculate the skewness and kurtosis of a dataset generated from a normal distribution.\n",
        "\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "# Generate data\n",
        "data = np.random.normal(0, 1, 1000)\n",
        "\n",
        "# Calculate skewness and kurtosis\n",
        "skewness = skew(data)\n",
        "kurt = kurtosis(data)  # default: Fisher's definition (normal=0)\n",
        "\n",
        "print(f\"Skewness: {skewness:.4f}\")\n",
        "print(f\"Kurtosis: {kurt:.4f}\")"
      ],
      "metadata": {
        "id": "ofFuOXeDqROj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "                              # Practical Part - 2"
      ],
      "metadata": {
        "id": "JwrvRUrg0TQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Write a Python program to perform a Z-test for comparing a sample mean to a known population mean and interpret the results.\n",
        "\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "sample = np.array([52, 50, 53, 49, 51, 50, 52, 51, 50, 48])\n",
        "population_mean = 50\n",
        "sample_mean = np.mean(sample)\n",
        "sample_std = np.std(sample, ddof=1)\n",
        "n = len(sample)\n",
        "\n",
        "# Calculate Z-score\n",
        "z_score = (sample_mean - population_mean) / (sample_std / np.sqrt(n))\n",
        "p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
        "\n",
        "print(f\"Z-Score: {z_score:.4f}\")\n",
        "print(f\"P-Value: {p_value:.4f}\")\n",
        "\n",
        "Interpretation:\n",
        "\n",
        "If p-value < 0.05 → reject the null hypothesis (mean is not 50).\n",
        "\n",
        "If p-value ≥ 0.05 → fail to reject H₀ (no evidence mean ≠ 50).\n",
        "\n"
      ],
      "metadata": {
        "id": "hqrGRcE-qWra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Simulate random data to perform hypothesis testing and calculate the corresponding P-value using Python.\n",
        "\n",
        "# Simulate data\n",
        "np.random.seed(42)\n",
        "data = np.random.normal(loc=5.1, scale=1.2, size=50)\n",
        "hypothesized_mean = 5.0\n",
        "\n",
        "# Perform one-sample t-test\n",
        "t_stat, p_value = stats.ttest_1samp(data, hypothesized_mean)\n",
        "\n",
        "print(f\"T-Statistic: {t_stat:.4f}\")\n",
        "print(f\"P-Value: {p_value:.4f}\")\n",
        "\n",
        "Interpretation: Checks if the sample mean significantly differs from the population mean (5.0).\n"
      ],
      "metadata": {
        "id": "LhvaWEJVq9J7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Implement a one-sample Z-test using Python to compare the sample mean with the population mean.\n",
        "\n",
        "# Same as Q1: Explicitly a one-sample Z-test\n",
        "def one_sample_z_test(sample, population_mean, population_std):\n",
        "    n = len(sample)\n",
        "    sample_mean = np.mean(sample)\n",
        "    z = (sample_mean - population_mean) / (population_std / np.sqrt(n))\n",
        "    p = 2 * (1 - stats.norm.cdf(abs(z)))\n",
        "    return z, p\n",
        "\n",
        "sample = np.random.normal(100, 15, 30)\n",
        "z_score, p_val = one_sample_z_test(sample, 100, 15)\n",
        "print(f\"Z-score: {z_score:.4f}, P-value: {p_val:.4f}\")"
      ],
      "metadata": {
        "id": "TTJ1Rpu-rFvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Perform a two-tailed Z-test using Python and visualize the decision region on a plot.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Values\n",
        "z_val = 2.1\n",
        "alpha = 0.05\n",
        "critical_value = stats.norm.ppf(1 - alpha / 2)\n",
        "\n",
        "# Plot\n",
        "x = np.linspace(-4, 4, 1000)\n",
        "y = stats.norm.pdf(x)\n",
        "plt.plot(x, y, label='Normal Distribution')\n",
        "\n",
        "# Critical regions\n",
        "plt.axvline(critical_value, color='red', linestyle='--', label='Critical value')\n",
        "plt.axvline(-critical_value, color='red', linestyle='--')\n",
        "plt.axvline(z_val, color='blue', linestyle='-', label='Z observed')\n",
        "\n",
        "plt.fill_between(x, y, where=(x > critical_value) | (x < -critical_value), color='red', alpha=0.2)\n",
        "plt.title('Two-tailed Z-Test Decision Region')\n",
        "plt.xlabel('Z')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8tHzyfBzrK57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Create a Python function that calculates and visualizes Type 1 and Type 2 errors during hypothesis testing.\n",
        "\n",
        "def visualize_errors(mu0=0, mu1=1, sigma=1, alpha=0.05, n=30):\n",
        "    from scipy.stats import norm\n",
        "    import matplotlib.pyplot as plt\n",
        "    se = sigma / np.sqrt(n)\n",
        "    z_critical = norm.ppf(1 - alpha)\n",
        "    x = np.linspace(-3, 5, 1000)\n",
        "\n",
        "    # Null and alternative distributions\n",
        "    null_dist = norm(loc=mu0, scale=se)\n",
        "    alt_dist = norm(loc=mu1, scale=se)\n",
        "\n",
        "    plt.plot(x, null_dist.pdf(x), label='Null Hypothesis (H₀)', color='blue')\n",
        "    plt.plot(x, alt_dist.pdf(x), label='Alternative Hypothesis (H₁)', color='green')\n",
        "\n",
        "    # Type I error region\n",
        "    plt.fill_between(x, null_dist.pdf(x), where=x > mu0 + z_critical * se, color='red', alpha=0.3, label='Type I Error (α)')\n",
        "\n",
        "    # Type II error region\n",
        "    plt.fill_between(x, alt_dist.pdf(x), where=x < mu0 + z_critical * se, color='orange', alpha=0.3, label='Type II Error (β)')\n",
        "\n",
        "    plt.axvline(mu0 + z_critical * se, color='black', linestyle='--', label='Critical Value')\n",
        "    plt.title('Type I and Type II Errors')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "visualize_errors()"
      ],
      "metadata": {
        "id": "3LG4l2pIrYtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Write a Python program to perform an independent T-test and interpret the results.\n",
        "\n",
        "from scipy.stats import ttest_1samp\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "data = np.random.normal(loc=10.5, scale=2, size=25)\n",
        "hypothesized_mean = 10\n",
        "\n",
        "# One-sample t-test\n",
        "t_stat, p_val = ttest_1samp(data, hypothesized_mean)\n",
        "\n",
        "print(f\"T-statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {p_val:.4f}\")\n",
        "\n",
        "Interpretation:\n",
        "\n",
        "If p < 0.05, reject H₀ → sample mean ≠ 10.\n",
        "\n",
        "If p ≥ 0.05, fail to reject H₀ → no significant difference.\n"
      ],
      "metadata": {
        "id": "mWHXrzbHrbWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Perform a paired sample T-test using Python and visualize the comparison results\n",
        "\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Sample data from two groups\n",
        "group1 = np.random.normal(loc=12, scale=3, size=30)\n",
        "group2 = np.random.normal(loc=14, scale=3, size=30)\n",
        "\n",
        "# Independent t-test (equal variance assumed)\n",
        "t_stat, p_val = ttest_ind(group1, group2)\n",
        "\n",
        "print(f\"T-statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {p_val:.4f}\")\n",
        "\n",
        "Interpretation:\n",
        "\n",
        "Tests whether the means of two independent samples are significantly different.\n",
        "\n",
        "Use equal_var=False if you suspect unequal variances.\n"
      ],
      "metadata": {
        "id": "GZTEZZe0s4SD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q 8. Simulate data and perform both Z-test and T-test, then compare the results using Python.\n",
        "data = np.random.normal(100, 15, 40)\n",
        "\n",
        "# Z-test\n",
        "z = (np.mean(data) - 100) / (15 / np.sqrt(len(data)))\n",
        "p_z = 2 * (1 - stats.norm.cdf(abs(z)))\n",
        "\n",
        "# T-test\n",
        "t_stat, p_t = stats.ttest_1samp(data, popmean=100)\n",
        "\n",
        "print(f\"Z-test p-value: {p_z:.4f}\")\n",
        "print(f\"T-test p-value: {p_t:.4f}\")"
      ],
      "metadata": {
        "id": "e0TJZgFPxoX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q 9: Write a Python function to calculate the confidence interval for a sample mean and explain its significanceE\n",
        "\n",
        "def confidence_interval(data, confidence=0.95):\n",
        "    mean = np.mean(data)\n",
        "    se = stats.sem(data)\n",
        "    interval = stats.t.interval(confidence, df=len(data)-1, loc=mean, scale=se)\n",
        "    return interval\n",
        "\n",
        "sample = np.random.normal(100, 10, 25)\n",
        "ci = confidence_interval(sample)\n",
        "print(f\"Confidence Interval: {ci}\")"
      ],
      "metadata": {
        "id": "BtySzDVQx8Sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q 10: Write a Python program to calculate the margin of error for a given confidence level using sample data.\n",
        "mean = 100\n",
        "se = 2\n",
        "confidence = 0.95\n",
        "\n",
        "margin = stats.t.ppf((1 + confidence) / 2, df=24) * se\n",
        "print(f\"Margin of Error: ±{margin:.2f}\")"
      ],
      "metadata": {
        "id": "GAj88v_gyL4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q 11:  Implement a Bayesian inference method using Bayes' Theorem in Python and explain the process.\n",
        "\n",
        "# Prior: P(Disease) = 0.01\n",
        "# P(Positive | Disease) = 0.99\n",
        "# P(Positive | No Disease) = 0.05\n",
        "\n",
        "P_D = 0.01\n",
        "P_pos_given_D = 0.99\n",
        "P_pos_given_not_D = 0.05\n",
        "P_not_D = 1 - P_D\n",
        "\n",
        "# Bayes' Theorem\n",
        "P_D_given_pos = (P_pos_given_D * P_D) / ((P_pos_given_D * P_D) + (P_pos_given_not_D * P_not_D))\n",
        "print(f\"Posterior Probability: {P_D_given_pos:.4f}\")"
      ],
      "metadata": {
        "id": "RzNh1cXDyZbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q 12: Perform a Chi-square test for independence between two categorical variables in Python.\n",
        "\n",
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Create a contingency table\n",
        "data = pd.DataFrame([[30, 10], [20, 40]], columns=[\"Success\", \"Fail\"], index=[\"Group A\", \"Group B\"])\n",
        "chi2, p, dof, expected = chi2_contingency(data)\n",
        "\n",
        "print(f\"Chi-square Statistic: {chi2:.4f}\")\n",
        "print(f\"P-value: {p:.4f}\")"
      ],
      "metadata": {
        "id": "25aly866yy5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q 13: Write a Python program to calculate the expected frequencies for a Chi-square test based on observed data.\n",
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "# Create a contingency table\n",
        "data = pd.DataFrame([[30, 10], [20, 40]], columns=[\"Success\", \"Fail\"], index=[\"Group A\", \"Group B\"])\n",
        "chi2, p, dof, expected = chi2_contingency(data).\n",
        "print(f\"Chi-square Statistic: {chi2:.4f}\")\n",
        "print(f\"P-value: {p:.4f}\")\n",
        "print(\"Expected Frequencies:\")\n",
        "print(expected)\n"
      ],
      "metadata": {
        "id": "9TCrR6klzXcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q 14: Perform a goodness-of-fit test using Python to compare the observed data to an expected distribution.\n",
        "observed = [18, 22, 20, 40]\n",
        "expected = [25, 25, 25, 25]\n",
        "\n",
        "chi2, p = stats.chisquare(f_obs=observed, f_exp=expected)\n",
        "\n",
        "print(f\"Chi-square Stat: {chi2:.4f}, P-value: {p:.4f}\")"
      ],
      "metadata": {
        "id": "0MbIf9Zo0BUR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}